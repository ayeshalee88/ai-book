"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[472],{15680:(n,e,t)=>{t.d(e,{xA:()=>p,yg:()=>f});var i=t(96540);function o(n,e,t){return e in n?Object.defineProperty(n,e,{value:t,enumerable:!0,configurable:!0,writable:!0}):n[e]=t,n}function a(n,e){var t=Object.keys(n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(n);e&&(i=i.filter(function(e){return Object.getOwnPropertyDescriptor(n,e).enumerable})),t.push.apply(t,i)}return t}function s(n){for(var e=1;e<arguments.length;e++){var t=null!=arguments[e]?arguments[e]:{};e%2?a(Object(t),!0).forEach(function(e){o(n,e,t[e])}):Object.getOwnPropertyDescriptors?Object.defineProperties(n,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach(function(e){Object.defineProperty(n,e,Object.getOwnPropertyDescriptor(t,e))})}return n}function r(n,e){if(null==n)return{};var t,i,o=function(n,e){if(null==n)return{};var t,i,o={},a=Object.keys(n);for(i=0;i<a.length;i++)t=a[i],e.indexOf(t)>=0||(o[t]=n[t]);return o}(n,e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(n);for(i=0;i<a.length;i++)t=a[i],e.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(n,t)&&(o[t]=n[t])}return o}var l=i.createContext({}),m=function(n){var e=i.useContext(l),t=e;return n&&(t="function"==typeof n?n(e):s(s({},e),n)),t},p=function(n){var e=m(n.components);return i.createElement(l.Provider,{value:e},n.children)},d="mdxType",c={inlineCode:"code",wrapper:function(n){var e=n.children;return i.createElement(i.Fragment,{},e)}},u=i.forwardRef(function(n,e){var t=n.components,o=n.mdxType,a=n.originalType,l=n.parentName,p=r(n,["components","mdxType","originalType","parentName"]),d=m(t),u=o,f=d["".concat(l,".").concat(u)]||d[u]||c[u]||a;return t?i.createElement(f,s(s({ref:e},p),{},{components:t})):i.createElement(f,s({ref:e},p))});function f(n,e){var t=arguments,o=e&&e.mdxType;if("string"==typeof n||o){var a=t.length,s=new Array(a);s[0]=u;var r={};for(var l in e)hasOwnProperty.call(e,l)&&(r[l]=e[l]);r.originalType=n,r[d]="string"==typeof n?n:o,s[1]=r;for(var m=2;m<a;m++)s[m]=t[m];return i.createElement.apply(null,s)}return i.createElement.apply(null,t)}u.displayName="MDXCreateElement"},77474:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>c,frontMatter:()=>a,metadata:()=>r,toc:()=>m});var i=t(58168),o=(t(96540),t(15680));const a={id:"simulation-environments",title:"Simulation Environments for Physical AI",sidebar_label:"Simulation Environments"},s="Simulation Environments for Physical AI",r={unversionedId:"tutorials/simulation-environments",id:"tutorials/simulation-environments",title:"Simulation Environments for Physical AI",description:"Introduction to Robotics Simulation",source:"@site/docs/tutorials/simulation-environments.md",sourceDirName:"tutorials",slug:"/tutorials/simulation-environments",permalink:"/ai-book/docs/tutorials/simulation-environments",draft:!1,editUrl:"https://github.com/ayeshalee88/ai-book/edit/main/docusaurus-book/docs/tutorials/simulation-environments.md",tags:[],version:"current",frontMatter:{id:"simulation-environments",title:"Simulation Environments for Physical AI",sidebar_label:"Simulation Environments"},sidebar:"tutorialSidebar",previous:{title:"Open Source Projects",permalink:"/ai-book/docs/case-studies/open-source-projects"},next:{title:"Hardware Integration",permalink:"/ai-book/docs/tutorials/hardware-integration"}},l={},m=[{value:"Introduction to Robotics Simulation",id:"introduction-to-robotics-simulation",level:2},{value:"Why Simulation is Important",id:"why-simulation-is-important",level:3},{value:"Simulation Fidelity Trade-offs",id:"simulation-fidelity-trade-offs",level:3},{value:"Gazebo: The ROS-Integrated Simulator",id:"gazebo-the-ros-integrated-simulator",level:2},{value:"Installation and Setup",id:"installation-and-setup",level:3},{value:"Basic Gazebo Concepts",id:"basic-gazebo-concepts",level:3},{value:"Creating a Simple World",id:"creating-a-simple-world",level:3},{value:"URDF Model Definition",id:"urdf-model-definition",level:3},{value:"Gazebo Controller Integration",id:"gazebo-controller-integration",level:3},{value:"Python Control Interface",id:"python-control-interface",level:3},{value:"PyBullet: Fast Physics Simulation",id:"pybullet-fast-physics-simulation",level:2},{value:"Installation",id:"installation",level:3},{value:"Basic PyBullet Usage",id:"basic-pybullet-usage",level:3},{value:"PyBullet for Reinforcement Learning",id:"pybullet-for-reinforcement-learning",level:3},{value:"Mujoco: High-Fidelity Physics",id:"mujoco-high-fidelity-physics",level:2},{value:"Mujoco Installation",id:"mujoco-installation",level:3},{value:"Mujoco XML Model Example",id:"mujoco-xml-model-example",level:3},{value:"Mujoco Python Control",id:"mujoco-python-control",level:3},{value:"Isaac Gym: GPU-Accelerated Simulation",id:"isaac-gym-gpu-accelerated-simulation",level:2},{value:"Isaac Gym Installation",id:"isaac-gym-installation",level:3},{value:"Isaac Gym Example",id:"isaac-gym-example",level:3},{value:"Best Practices for Simulation",id:"best-practices-for-simulation",level:2},{value:"Model Accuracy",id:"model-accuracy",level:3},{value:"Simulation Fidelity Considerations",id:"simulation-fidelity-considerations",level:3},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Hands-On Exercise",id:"hands-on-exercise",level:2}],p={toc:m},d="wrapper";function c({components:n,...e}){return(0,o.yg)(d,(0,i.A)({},p,e,{components:n,mdxType:"MDXLayout"}),(0,o.yg)("h1",{id:"simulation-environments-for-physical-ai"},"Simulation Environments for Physical AI"),(0,o.yg)("h2",{id:"introduction-to-robotics-simulation"},"Introduction to Robotics Simulation"),(0,o.yg)("p",null,"Simulation environments are crucial tools in physical AI development, allowing researchers and developers to test algorithms, train controllers, and validate designs before deploying on real hardware. This tutorial covers the most popular simulation environments used in humanoid robotics and embodied AI research."),(0,o.yg)("h3",{id:"why-simulation-is-important"},"Why Simulation is Important"),(0,o.yg)("p",null,"Simulation provides several key benefits for physical AI development:"),(0,o.yg)("ol",null,(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("strong",{parentName:"li"},"Safety"),": Test dangerous behaviors without risk to hardware or humans"),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("strong",{parentName:"li"},"Cost-Effectiveness"),": Reduce the need for expensive physical prototypes"),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("strong",{parentName:"li"},"Speed"),": Run experiments faster than real-time"),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("strong",{parentName:"li"},"Reproducibility"),": Create consistent testing conditions"),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("strong",{parentName:"li"},"Iteration"),": Rapidly test and refine algorithms")),(0,o.yg)("h3",{id:"simulation-fidelity-trade-offs"},"Simulation Fidelity Trade-offs"),(0,o.yg)("p",null,"When choosing a simulation environment, consider the trade-offs between:"),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Accuracy vs. Speed"),": More accurate physics requires more computation"),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Realism vs. Simplification"),": Complex environments may slow development"),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Development Time vs. Quality"),": Higher fidelity simulations take longer to set up")),(0,o.yg)("h2",{id:"gazebo-the-ros-integrated-simulator"},"Gazebo: The ROS-Integrated Simulator"),(0,o.yg)("p",null,"Gazebo is the most popular simulation environment for ROS-based robotics projects, offering high-fidelity physics simulation and extensive sensor modeling."),(0,o.yg)("h3",{id:"installation-and-setup"},"Installation and Setup"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"# Install Gazebo on Ubuntu with ROS\nsudo apt update\nsudo apt install gazebo11 libgazebo11-dev\n\n# If using ROS Noetic\nsudo apt install ros-noetic-gazebo-ros-pkgs ros-noetic-gazebo-ros-control\n")),(0,o.yg)("h3",{id:"basic-gazebo-concepts"},"Basic Gazebo Concepts"),(0,o.yg)("p",null,"Gazebo operates on several core concepts:"),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Worlds"),": Environments containing models and physics properties"),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Models"),": Physical objects with URDF/SDF definitions"),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Plugins"),": Custom code that extends simulation capabilities"),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Sensors"),": Simulated sensor devices (cameras, IMUs, LIDAR, etc.)")),(0,o.yg)("h3",{id:"creating-a-simple-world"},"Creating a Simple World"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-xml"},'\x3c!-- simple_world.world --\x3e\n<?xml version="1.0" ?>\n<sdf version="1.6">\n  <world name="simple_world">\n    \x3c!-- Physics engine --\x3e\n    <physics type="ode">\n      <max_step_size>0.001</max_step_size>\n      <real_time_factor>1</real_time_factor>\n      <real_time_update_rate>1000</real_time_update_rate>\n    </physics>\n\n    \x3c!-- Ground plane --\x3e\n    <include>\n      <uri>model://ground_plane</uri>\n    </include>\n\n    \x3c!-- Sun light --\x3e\n    <include>\n      <uri>model://sun</uri>\n    </include>\n\n    \x3c!-- Your robot model would be included here --\x3e\n    <include>\n      <uri>model://your_robot</uri>\n      <pose>0 0 1 0 0 0</pose>\n    </include>\n\n    \x3c!-- Optional: Additional objects --\x3e\n    <model name="box">\n      <pose>2 0 0.5 0 0 0</pose>\n      <link name="link">\n        <collision name="collision">\n          <geometry>\n            <box>\n              <size>1 1 1</size>\n            </box>\n          </geometry>\n        </collision>\n        <visual name="visual">\n          <geometry>\n            <box>\n              <size>1 1 1</size>\n            </box>\n          </geometry>\n          <material>\n            <ambient>0.5 0.5 0.5 1</ambient>\n            <diffuse>0.8 0.8 0.8 1</diffuse>\n          </material>\n        </visual>\n        <inertial>\n          <mass>1.0</mass>\n          <inertia>\n            <ixx>0.1667</ixx>\n            <ixy>0</ixy>\n            <ixz>0</ixz>\n            <iyy>0.1667</iyy>\n            <iyz>0</iyz>\n            <izz>0.1667</izz>\n          </inertia>\n        </inertial>\n      </link>\n    </model>\n  </world>\n</sdf>\n')),(0,o.yg)("h3",{id:"urdf-model-definition"},"URDF Model Definition"),(0,o.yg)("p",null,"URDF (Unified Robot Description Format) is commonly used with Gazebo:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-xml"},'<?xml version="1.0"?>\n<robot name="simple_humanoid" xmlns:xacro="http://www.ros.org/wiki/xacro">\n  \x3c!-- Base/Body link --\x3e\n  <link name="base_link">\n    <visual>\n      <geometry>\n        <box size="0.3 0.2 0.4"/>\n      </geometry>\n      <material name="blue">\n        <color rgba="0 0 1 1"/>\n      </material>\n    </visual>\n    <collision>\n      <geometry>\n        <box size="0.3 0.2 0.4"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="5.0"/>\n      <inertia ixx="0.2" ixy="0" ixz="0" iyy="0.3" iyz="0" izz="0.4"/>\n    </inertial>\n  </link>\n\n  \x3c!-- Head --\x3e\n  <link name="head">\n    <visual>\n      <geometry>\n        <sphere radius="0.1"/>\n      </geometry>\n      <material name="white">\n        <color rgba="1 1 1 1"/>\n      </material>\n    </visual>\n    <collision>\n      <geometry>\n        <sphere radius="0.1"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="1.0"/>\n      <inertia ixx="0.004" ixy="0" ixz="0" iyy="0.004" iyz="0" izz="0.004"/>\n    </inertial>\n  </link>\n\n  <joint name="neck_joint" type="revolute">\n    <parent link="base_link"/>\n    <child link="head"/>\n    <origin xyz="0 0 0.3" rpy="0 0 0"/>\n    <axis xyz="0 1 0"/>\n    <limit lower="-1.57" upper="1.57" effort="100" velocity="3"/>\n    <dynamics damping="1" friction="0.1"/>\n  </joint>\n\n  \x3c!-- Left leg --\x3e\n  <link name="left_hip">\n    <visual>\n      <geometry>\n        <cylinder length="0.4" radius="0.05"/>\n      </geometry>\n      <material name="gray">\n        <color rgba="0.5 0.5 0.5 1"/>\n      </material>\n    </visual>\n    <collision>\n      <geometry>\n        <cylinder length="0.4" radius="0.05"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="2.0"/>\n      <inertia ixx="0.027" ixy="0" ixz="0" iyy="0.025" iyz="0" izz="0.005"/>\n    </inertial>\n  </link>\n\n  <joint name="left_hip_joint" type="revolute">\n    <parent link="base_link"/>\n    <child link="left_hip"/>\n    <origin xyz="-0.1 0 -0.3" rpy="0 0 0"/>\n    <axis xyz="1 0 0"/>\n    <limit lower="-1.57" upper="1.57" effort="200" velocity="2"/>\n    <dynamics damping="2" friction="0.2"/>\n  </joint>\n\n  \x3c!-- Additional joints and links would continue similarly --\x3e\n\n  \x3c!-- Gazebo-specific tags for simulation --\x3e\n  <gazebo reference="base_link">\n    <material>Gazebo/Blue</material>\n  </gazebo>\n\n  <gazebo reference="head">\n    <material>Gazebo/White</material>\n  </gazebo>\n\n  <gazebo reference="left_hip">\n    <material>Gazebo/Gray</material>\n  </gazebo>\n\n  \x3c!-- Transmission for ROS control --\x3e\n  <transmission name="left_hip_trans">\n    <type>transmission_interface/SimpleTransmission</type>\n    <joint name="left_hip_joint">\n      <hardwareInterface>hardware_interface/PositionJointInterface</hardwareInterface>\n    </joint>\n    <actuator name="left_hip_motor">\n      <hardwareInterface>hardware_interface/PositionJointInterface</hardwareInterface>\n      <mechanicalReduction>1</mechanicalReduction>\n    </actuator>\n  </transmission>\n</robot>\n')),(0,o.yg)("h3",{id:"gazebo-controller-integration"},"Gazebo Controller Integration"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-cpp"},'// Example Gazebo plugin for joint control\n#include <gazebo/gazebo.hh>\n#include <gazebo/physics/physics.hh>\n#include <gazebo/common/common.hh>\n#include <stdio.h>\n\nnamespace gazebo\n{\n  class JointControlPlugin : public ModelPlugin\n  {\n    public: void Load(physics::ModelPtr _parent, sdf::ElementPtr /*_sdf*/)\n    {\n      // Store the model pointer for convenience\n      this->model = _parent;\n\n      // Get the joint\n      this->joint = this->model->GetJoint("left_hip_joint");\n\n      // Listen to the update event. This event is broadcast every\n      // simulation iteration.\n      this->updateConnection = event::Events::ConnectWorldUpdateBegin(\n          std::bind(&JointControlPlugin::OnUpdate, this));\n    }\n\n    // Called by the world update start event\n    public: void OnUpdate()\n    {\n      // Apply a small sine wave torque to the joint\n      double torque = 0.1 * sin(gazebo::common::Time::GetWallTime().Double());\n      this->joint->SetForce(0, torque);\n    }\n\n    // Pointer to the model\n    private: physics::ModelPtr model;\n\n    // Pointer to the joint\n    private: physics::JointPtr joint;\n\n    // Event connection\n    private: event::ConnectionPtr updateConnection;\n  };\n\n  // Register this plugin with the simulator\n  GZ_REGISTER_MODEL_PLUGIN(JointControlPlugin)\n}\n')),(0,o.yg)("h3",{id:"python-control-interface"},"Python Control Interface"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-python"},"#!/usr/bin/env python3\nimport rospy\nfrom std_msgs.msg import Float64\nfrom sensor_msgs.msg import JointState\nfrom trajectory_msgs.msg import JointTrajectory, JointTrajectoryPoint\nimport math\n\nclass GazeboController:\n    def __init__(self):\n        rospy.init_node('gazebo_controller', anonymous=True)\n\n        # Publishers for joint commands\n        self.joint_publishers = {\n            'left_hip_joint': rospy.Publisher('/simple_humanoid/left_hip_joint_position_controller/command',\n                                            Float64, queue_size=10),\n            'right_hip_joint': rospy.Publisher('/simple_humanoid/right_hip_joint_position_controller/command',\n                                             Float64, queue_size=10),\n            # Add more joints as needed\n        }\n\n        # Subscriber for joint states\n        self.joint_state_sub = rospy.Subscriber('/joint_states', JointState, self.joint_state_callback)\n\n        self.current_joint_states = JointState()\n\n        # Timer for control loop\n        self.control_timer = rospy.Timer(rospy.Duration(0.01), self.control_loop)  # 100 Hz\n\n    def joint_state_callback(self, msg):\n        \"\"\"Callback for joint state updates\"\"\"\n        self.current_joint_states = msg\n\n    def control_loop(self, event):\n        \"\"\"Main control loop\"\"\"\n        # Simple walking pattern\n        t = rospy.Time.now().to_sec()\n\n        # Generate walking motion\n        left_hip_pos = 0.2 * math.sin(t * 2)  # 2 rad/s oscillation\n        right_hip_pos = 0.2 * math.sin(t * 2 + math.pi)  # Opposite phase\n\n        # Publish commands\n        self.joint_publishers['left_hip_joint'].publish(Float64(left_hip_pos))\n        self.joint_publishers['right_hip_joint'].publish(Float64(right_hip_pos))\n\n    def move_to_pose(self, joint_positions, duration=5.0):\n        \"\"\"Move robot to specified joint positions using trajectory controller\"\"\"\n        trajectory_pub = rospy.Publisher('/simple_humanoid/joint_trajectory_controller/command',\n                                       JointTrajectory, queue_size=10)\n\n        traj = JointTrajectory()\n        traj.joint_names = list(joint_positions.keys())\n\n        point = JointTrajectoryPoint()\n        point.positions = list(joint_positions.values())\n        point.velocities = [0.0] * len(joint_positions)\n        point.time_from_start = rospy.Duration(duration)\n\n        traj.points = [point]\n        traj.header.stamp = rospy.Time.now()\n\n        trajectory_pub.publish(traj)\n\nif __name__ == '__main__':\n    try:\n        controller = GazeboController()\n        rospy.spin()\n    except rospy.ROSInterruptException:\n        pass\n")),(0,o.yg)("h2",{id:"pybullet-fast-physics-simulation"},"PyBullet: Fast Physics Simulation"),(0,o.yg)("p",null,"PyBullet is a Python-based physics engine that provides fast simulation with good integration for machine learning applications."),(0,o.yg)("h3",{id:"installation"},"Installation"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"pip install pybullet\n")),(0,o.yg)("h3",{id:"basic-pybullet-usage"},"Basic PyBullet Usage"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-python"},'import pybullet as p\nimport pybullet_data\nimport numpy as np\nimport time\n\nclass PyBulletRobot:\n    def __init__(self, urdf_path="robot.urdf", gui=True):\n        # Connect to physics server\n        if gui:\n            self.physics_client = p.connect(p.GUI)\n        else:\n            self.physics_client = p.connect(p.DIRECT)\n\n        # Set gravity\n        p.setGravity(0, 0, -9.81)\n\n        # Load plane\n        p.setAdditionalSearchPath(pybullet_data.getDataPath())\n        self.plane_id = p.loadURDF("plane.urdf")\n\n        # Load robot\n        self.robot_id = p.loadURDF(urdf_path, [0, 0, 1])\n\n        # Get joint information\n        self.joint_info = {}\n        self.motor_joints = []\n        for i in range(p.getNumJoints(self.robot_id)):\n            joint_info = p.getJointInfo(self.robot_id, i)\n            joint_name = joint_info[1].decode(\'utf-8\')\n            joint_type = joint_info[2]\n\n            if joint_type == p.JOINT_REVOLUTE or joint_type == p.JOINT_PRISMATIC:\n                self.motor_joints.append(i)\n                self.joint_info[i] = {\n                    \'name\': joint_name,\n                    \'type\': joint_type,\n                    \'lower_limit\': joint_info[8],\n                    \'upper_limit\': joint_info[9],\n                    \'max_force\': joint_info[10],\n                    \'max_velocity\': joint_info[11]\n                }\n\n        print(f"Loaded robot with {len(self.motor_joints)} motor joints")\n\n    def set_joint_positions(self, joint_positions):\n        """Set target positions for all joints"""\n        for i, joint_id in enumerate(self.motor_joints):\n            p.setJointMotorControl2(\n                bodyIndex=self.robot_id,\n                jointIndex=joint_id,\n                controlMode=p.POSITION_CONTROL,\n                targetPosition=joint_positions[i],\n                force=self.joint_info[joint_id][\'max_force\']\n            )\n\n    def set_joint_velocities(self, joint_velocities):\n        """Set target velocities for all joints"""\n        for i, joint_id in enumerate(self.motor_joints):\n            p.setJointMotorControl2(\n                bodyIndex=self.robot_id,\n                jointIndex=joint_id,\n                controlMode=p.VELOCITY_CONTROL,\n                targetVelocity=joint_velocities[i],\n                force=self.joint_info[joint_id][\'max_force\']\n            )\n\n    def set_joint_torques(self, joint_torques):\n        """Apply torques to all joints"""\n        p.setJointMotorControlArray(\n            bodyIndex=self.robot_id,\n            jointIndices=self.motor_joints,\n            controlMode=p.TORQUE_CONTROL,\n            forces=joint_torques\n        )\n\n    def get_joint_states(self):\n        """Get current joint positions and velocities"""\n        joint_states = p.getJointStates(self.robot_id, self.motor_joints)\n        positions = [state[0] for state in joint_states]\n        velocities = [state[1] for state in joint_states]\n        return positions, velocities\n\n    def get_link_state(self, link_index):\n        """Get position and orientation of a specific link"""\n        return p.getLinkState(self.robot_id, link_index)\n\n    def step_simulation(self):\n        """Step the simulation forward"""\n        p.stepSimulation()\n        time.sleep(1./240.)  # Real-time simulation at 240 Hz\n\n    def reset_robot(self, position=[0, 0, 1]):\n        """Reset robot to initial position"""\n        p.resetBasePositionAndOrientation(self.robot_id, position, [0, 0, 0, 1])\n        # Reset joint positions to zero\n        for joint_id in self.motor_joints:\n            p.resetJointState(self.robot_id, joint_id, 0)\n\n    def add_obstacle(self, position, size=[1, 1, 1]):\n        """Add a box obstacle to the environment"""\n        colBoxId = p.createCollisionShape(p.GEOM_BOX, halfExtents=size)\n        visualShapeId = p.createVisualShape(p.GEOM_BOX, halfExtents=size, rgbaColor=[1, 0, 0, 1])\n        obstacle_id = p.createMultiBody(baseMass=0, baseCollisionShapeIndex=colBoxId,\n                                       baseVisualShapeIndex=visualShapeId, basePosition=position)\n        return obstacle_id\n\n    def disconnect(self):\n        """Disconnect from physics server"""\n        p.disconnect(self.physics_client)\n\n# Example usage\ndef main():\n    # Create simulation\n    robot_sim = PyBulletRobot(gui=True)\n\n    # Add some obstacles\n    robot_sim.add_obstacle([2, 0, 0.5], [0.2, 0.2, 0.5])\n    robot_sim.add_obstacle([-1, 1, 0.5], [0.3, 0.3, 0.5])\n\n    # Simple control loop\n    for i in range(1000):\n        # Simple walking pattern\n        t = i / 240.0  # Time in seconds (240 Hz)\n\n        # Generate joint positions for walking\n        joint_positions = [0] * len(robot_sim.motor_joints)\n        if len(joint_positions) >= 2:\n            joint_positions[0] = 0.2 * np.sin(t * 2)  # Left hip\n            joint_positions[1] = -0.2 * np.sin(t * 2)  # Right hip (opposite phase)\n\n        robot_sim.set_joint_positions(joint_positions)\n        robot_sim.step_simulation()\n\n    robot_sim.disconnect()\n\nif __name__ == "__main__":\n    main()\n')),(0,o.yg)("h3",{id:"pybullet-for-reinforcement-learning"},"PyBullet for Reinforcement Learning"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-python"},'import pybullet as p\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass PyBulletEnvironment:\n    def __init__(self, robot_urdf, gui=False):\n        self.robot_urdf = robot_urdf\n        self.physics_client = p.connect(p.GUI if gui else p.DIRECT)\n        p.setGravity(0, 0, -9.81)\n        p.setAdditionalSearchPath(pybullet_data.getDataPath())\n\n        # Load plane and robot\n        self.plane_id = p.loadURDF("plane.urdf")\n        self.robot_id = p.loadURDF(robot_urdf, [0, 0, 1])\n\n        # Get motor joints\n        self.motor_joints = []\n        for i in range(p.getNumJoints(self.robot_id)):\n            joint_info = p.getJointInfo(self.robot_id, i)\n            if joint_info[2] in [p.JOINT_REVOLUTE, p.JOINT_PRISMATIC]:\n                self.motor_joints.append(i)\n\n        self.reset()\n\n    def reset(self):\n        """Reset environment to initial state"""\n        p.resetBasePositionAndOrientation(self.robot_id, [0, 0, 1], [0, 0, 0, 1])\n\n        # Reset all joints to zero\n        for joint_id in self.motor_joints:\n            p.resetJointState(self.robot_id, joint_id, 0)\n\n        return self.get_observation()\n\n    def get_observation(self):\n        """Get current observation from environment"""\n        # Get joint states\n        joint_states = p.getJointStates(self.robot_id, self.motor_joints)\n        joint_positions = [state[0] for state in joint_states]\n        joint_velocities = [state[1] for state in joint_states]\n\n        # Get base position and orientation\n        pos, orn = p.getBasePositionAndOrientation(self.robot_id)\n        lin_vel, ang_vel = p.getBaseVelocity(self.robot_id)\n\n        # Combine into observation vector\n        observation = np.concatenate([\n            joint_positions,\n            joint_velocities,\n            pos,  # Base position\n            orn,  # Base orientation\n            lin_vel,  # Base linear velocity\n            ang_vel   # Base angular velocity\n        ])\n\n        return observation\n\n    def step(self, action):\n        """Execute action and return (observation, reward, done, info)"""\n        # Apply action (torques or positions)\n        # Here we\'ll use position control with the action as target positions\n        for i, joint_id in enumerate(self.motor_joints):\n            if i < len(action):\n                p.setJointMotorControl2(\n                    bodyIndex=self.robot_id,\n                    jointIndex=joint_id,\n                    controlMode=p.POSITION_CONTROL,\n                    targetPosition=action[i],\n                    force=100  # Max force\n                )\n\n        # Step simulation\n        p.stepSimulation()\n\n        # Get new observation\n        observation = self.get_observation()\n\n        # Calculate reward (example: move forward)\n        pos, _ = p.getBasePositionAndOrientation(self.robot_id)\n        reward = pos[0] * 0.1  # Positive X is forward, reward for forward movement\n\n        # Check if episode is done (example: robot fell)\n        done = pos[2] < 0.3  # If robot height is too low, it probably fell\n\n        info = {}  # Additional information\n\n        return observation, reward, done, info\n\n    def close(self):\n        """Close the environment"""\n        p.disconnect(self.physics_client)\n\n# Example: Simple policy network for PyBullet environment\nclass PolicyNetwork(nn.Module):\n    def __init__(self, state_dim, action_dim, hidden_dim=64):\n        super(PolicyNetwork, self).__init__()\n\n        self.network = nn.Sequential(\n            nn.Linear(state_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, action_dim),\n            nn.Tanh()  # Actions are bounded to [-1, 1]\n        )\n\n    def forward(self, state):\n        return self.network(state)\n\n# Example: Simple policy gradient training\ndef train_simple_policy():\n    env = PyBulletEnvironment("simple_robot.urdf", gui=False)\n\n    state_dim = len(env.get_observation())\n    action_dim = len(env.motor_joints)\n\n    policy = PolicyNetwork(state_dim, action_dim)\n    optimizer = optim.Adam(policy.parameters(), lr=1e-3)\n\n    # Training loop (simplified)\n    for episode in range(100):\n        state = env.reset()\n        total_reward = 0\n\n        for step in range(200):  # Max steps per episode\n            state_tensor = torch.FloatTensor(state)\n            action = policy(state_tensor).detach().numpy()\n\n            next_state, reward, done, _ = env.step(action)\n            total_reward += reward\n\n            if done:\n                break\n\n            state = next_state\n\n        print(f"Episode {episode}, Total Reward: {total_reward:.2f}")\n\n    env.close()\n')),(0,o.yg)("h2",{id:"mujoco-high-fidelity-physics"},"Mujoco: High-Fidelity Physics"),(0,o.yg)("p",null,"Mujoco (Multi-Joint dynamics with Contact) is a commercial physics engine known for high-fidelity simulation."),(0,o.yg)("h3",{id:"mujoco-installation"},"Mujoco Installation"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"pip install mujoco\n")),(0,o.yg)("h3",{id:"mujoco-xml-model-example"},"Mujoco XML Model Example"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-xml"},'\x3c!-- simple_humanoid.xml --\x3e\n<mujoco model="simple_humanoid">\n  <compiler angle="degree" inertiafromgeom="true"/>\n  <default>\n    <joint armature="1" damping="1" limited="true"/>\n    <geom friction="0.8 0.1 0.1" margin="0.001" rgba="0.8 0.6 0.4 1"/>\n  </default>\n\n  <option integrator="RK4" timestep="0.002"/>\n\n  <worldbody>\n    <light directional="false" diffuse=".8 .8 .8" specular=".2 .2 .2" pos="0 0 3" dir="0 0 -1"/>\n    <geom name="floor" type="plane" pos="0 0 0" size="5 5 0.1" rgba="0.9 0.9 0.9 1"/>\n\n    <body name="torso" pos="0 0 1.2">\n      <geom name="torso_geom" type="capsule" fromto="0 0 -0.1 0 0 0.1" size="0.15"/>\n      <joint name="root" type="free" pos="0 0 0"/>\n\n      <body name="head" pos="0 0 0.2">\n        <geom name="head_geom" type="sphere" size="0.1"/>\n      </body>\n\n      <body name="right_thigh" pos="0 -0.1 -0.2">\n        <geom name="right_thigh_geom" type="capsule" fromto="0 0 0 0 0 -0.3" size="0.06"/>\n        <joint name="right_hip" type="hinge" pos="0 0 0" axis="0 1 0" range="-20 100"/>\n\n        <body name="right_shin" pos="0 0 -0.6">\n          <geom name="right_shin_geom" type="capsule" fromto="0 0 0 0 0 -0.3" size="0.05"/>\n          <joint name="right_knee" type="hinge" pos="0 0 0.02" axis="0 1 0" range="-150 0"/>\n\n          <body name="right_foot" pos="0 0 -0.35">\n            <geom name="right_foot_geom" type="box" size="0.1 0.025 0.05" pos="0 0 0.025"/>\n            <joint name="right_ankle" type="hinge" pos="0 0 0.05" axis="0 1 0" range="-45 45"/>\n          </body>\n        </body>\n      </body>\n\n      <body name="left_thigh" pos="0 0.1 -0.2">\n        <geom name="left_thigh_geom" type="capsule" fromto="0 0 0 0 0 -0.3" size="0.06"/>\n        <joint name="left_hip" type="hinge" pos="0 0 0" axis="0 1 0" range="-20 100"/>\n\n        <body name="left_shin" pos="0 0 -0.6">\n          <geom name="left_shin_geom" type="capsule" fromto="0 0 0 0 0 -0.3" size="0.05"/>\n          <joint name="left_knee" type="hinge" pos="0 0 0.02" axis="0 1 0" range="-150 0"/>\n\n          <body name="left_foot" pos="0 0 -0.35">\n            <geom name="left_foot_geom" type="box" size="0.1 0.025 0.05" pos="0 0 0.025"/>\n            <joint name="left_ankle" type="hinge" pos="0 0 0.05" axis="0 1 0" range="-45 45"/>\n          </body>\n        </body>\n      </body>\n    </body>\n  </worldbody>\n\n  <actuator>\n    <motor name="right_hip" joint="right_hip" gear="100"/>\n    <motor name="right_knee" joint="right_knee" gear="100"/>\n    <motor name="right_ankle" joint="right_ankle" gear="50"/>\n    <motor name="left_hip" joint="left_hip" gear="100"/>\n    <motor name="left_knee" joint="left_knee" gear="100"/>\n    <motor name="left_ankle" joint="left_ankle" gear="50"/>\n  </actuator>\n</mujoco>\n')),(0,o.yg)("h3",{id:"mujoco-python-control"},"Mujoco Python Control"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-python"},'import mujoco\nimport mujoco.viewer\nimport numpy as np\n\nclass MujocoHumanoid:\n    def __init__(self, model_path="simple_humanoid.xml"):\n        self.model = mujoco.MjModel.from_xml_path(model_path)\n        self.data = mujoco.MjData(self.model)\n\n        # Initialize the model\n        mujoco.mj_forward(self.model, self.data)\n\n    def reset(self):\n        """Reset the simulation to initial state"""\n        mujoco.mj_resetData(self.model, self.data)\n        mujoco.mj_forward(self.model, self.data)\n\n    def step(self, action):\n        """Step the simulation with given actions"""\n        # Set control signals\n        self.data.ctrl[:] = action\n\n        # Step simulation\n        mujoco.mj_step(self.model, self.data)\n\n    def get_observation(self):\n        """Get current observation"""\n        # Example observation: joint positions, velocities, body positions\n        obs = np.concatenate([\n            self.data.qpos,  # Joint positions\n            self.data.qvel,  # Joint velocities\n            self.data.body("torso").xpos,  # Torso position\n            self.data.body("torso").xquat, # Torso orientation\n        ])\n        return obs\n\n    def get_reward(self):\n        """Calculate reward (example: forward velocity)"""\n        # Reward for moving forward\n        torso_vel = self.data.body("torso").cvel[1]  # Linear velocity in x direction\n        reward = torso_vel * 0.1\n\n        # Small penalty for large torques\n        torque_penalty = -0.001 * np.sum(np.square(self.data.ctrl))\n        reward += torque_penalty\n\n        return reward\n\n    def render(self):\n        """Render the simulation"""\n        # This would typically be used with mujoco.viewer\n        pass\n\n# Example usage\ndef run_mujoco_simulation():\n    humanoid = MujocoHumanoid()\n\n    # Run simulation with simple controller\n    for i in range(1000):\n        # Simple controller: move legs in alternating pattern\n        t = i * 0.002  # Assuming 0.002s timestep\n\n        action = np.array([\n            0.2 * np.sin(t * 5),    # Right hip\n            -0.3 * np.sin(t * 5),   # Right knee\n            0.1 * np.sin(t * 5),    # Right ankle\n            0.2 * np.sin(t * 5 + np.pi),  # Left hip (opposite phase)\n            -0.3 * np.sin(t * 5 + np.pi), # Left knee\n            0.1 * np.sin(t * 5 + np.pi),  # Left ankle\n        ])\n\n        humanoid.step(action)\n\n        # Print reward every 100 steps\n        if i % 100 == 0:\n            reward = humanoid.get_reward()\n            print(f"Step {i}, Reward: {reward:.3f}")\n\n    print("Simulation completed")\n\n# Run with viewer\ndef run_with_viewer():\n    humanoid = MujocoHumanoid()\n\n    with mujoco.viewer.launch_passive(humanoid.model, humanoid.data) as viewer:\n        while viewer.is_running():\n            # Simple walking controller\n            t = humanoid.data.time\n            action = np.array([\n                0.2 * np.sin(t * 5),\n                -0.3 * np.sin(t * 5),\n                0.1 * np.sin(t * 5),\n                0.2 * np.sin(t * 5 + np.pi),\n                -0.3 * np.sin(t * 5 + np.pi),\n                0.1 * np.sin(t * 5 + np.pi),\n            ])\n\n            humanoid.step(action)\n            viewer.sync()\n')),(0,o.yg)("h2",{id:"isaac-gym-gpu-accelerated-simulation"},"Isaac Gym: GPU-Accelerated Simulation"),(0,o.yg)("p",null,"Isaac Gym provides GPU-accelerated simulation for large-scale RL training."),(0,o.yg)("h3",{id:"isaac-gym-installation"},"Isaac Gym Installation"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"# Isaac Gym is part of NVIDIA Omniverse\n# Download from NVIDIA Developer website\n# pip install -e . # in the Isaac Gym installation directory\n")),(0,o.yg)("h3",{id:"isaac-gym-example"},"Isaac Gym Example"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-python"},'import isaacgym\nimport torch\nimport numpy as np\n\n# Import required Isaac Gym features\nfrom isaacgym.torch_utils import *\nfrom isaacgym import gymtorch, gymapi\n\nclass IsaacGymHumanoid:\n    def __init__(self, headless=True):\n        # Initialize gym\n        self.gym = gymapi.acquire_gym()\n\n        # Configure sim\n        sim_params = gymapi.SimParams()\n        sim_params.dt = 1.0 / 60.0\n        sim_params.up_axis = gymapi.UP_AXIS_Z\n        sim_params.gravity = gymapi.Vec3(0, 0, -9.81)\n\n        # Set physics engine parameters\n        sim_params.physx.solver_type = 1\n        sim_params.physx.num_position_iterations = 8\n        sim_params.physx.num_velocity_iterations = 1\n        sim_params.physx.max_gpu_contact_pairs = 8 * 1024 * 1024\n        sim_params.physx.num_threads = 4\n        sim_params.physx.rest_offset = 0.0\n        sim_params.physx.contact_offset = 0.02\n        sim_params.physx.friction_offset_threshold = 0.01\n\n        # Create sim\n        self.sim = self.gym.create_sim(0, 0, gymapi.SIM_PHYSX, sim_params)\n        if self.sim is None:\n            print("*** Failed to create sim")\n            quit()\n\n        # Create viewer\n        if not headless:\n            self.viewer = self.gym.create_viewer(self.sim, gymapi.Vec3(5, 5, 1))\n            if self.viewer is None:\n                print("*** Failed to create viewer")\n                quit()\n        else:\n            self.viewer = None\n\n        # Initialize environments\n        self._create_envs()\n\n    def _create_envs(self):\n        # Set default environment spacing\n        spacing = 2.0\n        env_lower = gymapi.Vec3(-spacing, -spacing, 0.0)\n        env_upper = gymapi.Vec3(spacing, spacing, spacing)\n\n        # Load robot asset\n        asset_root = "path/to/assets"\n        asset_file = "simple_humanoid.urdf"\n\n        asset_options = gymapi.AssetOptions()\n        asset_options.fix_base_link = False\n        asset_options.disable_gravity = False\n        asset_options.thickness = 0.001\n        asset_options.angular_damping = 0.0\n        asset_options.linear_damping = 0.0\n\n        print("Loading asset \'%s\' from \'%s\'" % (asset_file, asset_root))\n        self.humanoid_asset = self.gym.load_asset(self.sim, asset_root, asset_file, asset_options)\n\n        # Create environment\n        num_envs = 1\n        self.envs = []\n        for i in range(num_envs):\n            # Create environment\n            env = self.gym.create_env(self.sim, env_lower, env_upper, 1)\n            self.envs.append(env)\n\n            # Add robot to environment\n            pose = gymapi.Transform()\n            pose.p = gymapi.Vec3(0.0, 0.0, 1.0)\n            pose.r = gymapi.Quat(0.0, 0.0, 0.0, 1.0)\n\n            # Add robot to environment\n            humanoid_handle = self.gym.create_actor(env, self.humanoid_asset, pose, "humanoid", i, 1, 0)\n\n            # Store the number of DOFs\n            self.num_dofs = self.gym.get_actor_dof_count(env, humanoid_handle)\n\n            # Set DOF properties\n            dof_props = self.gym.get_actor_dof_properties(env, humanoid_handle)\n            dof_props["driveMode"] = gymapi.DOF_MODE_EFFORT\n            dof_props["stiffness"] = 0.0\n            dof_props["damping"] = 0.1\n            self.gym.set_actor_dof_properties(env, humanoid_handle, dof_props)\n\n            # Initialize DOF control\n            self.pos_action = torch.zeros((len(self.envs), self.num_dofs), dtype=torch.float32, device="cpu")\n            self.effort_action = torch.zeros((len(self.envs), self.num_dofs), dtype=torch.float32, device="cpu")\n\n    def step(self, actions):\n        """Step the simulation with actions"""\n        # Set actions\n        self.effort_action[:] = torch.tensor(actions, dtype=torch.float32)\n\n        # Apply actions\n        for i, env in enumerate(self.envs):\n            actor_handle = self.gym.get_actor_handle(env, 0)\n            self.gym.apply_actor_dof_efforts(env, actor_handle, self.effort_action[i].numpy())\n\n        # Step simulation\n        self.gym.simulate(self.sim)\n        self.gym.fetch_results(self.sim, True)\n\n        # Update viewer\n        if self.viewer:\n            self.gym.step_graphics(self.sim)\n            self.gym.draw_viewer(self.viewer, self.sim, False)\n\n    def reset(self):\n        """Reset all environments"""\n        pass\n\n    def get_observation(self):\n        """Get current observations"""\n        obs = []\n        for env in self.envs:\n            # Get actor state\n            actor_handle = self.gym.get_actor_handle(env, 0)\n            actor_rigid_body_states = self.gym.get_actor_rigid_body_states(env, actor_handle, gymapi.STATE_POS)\n            obs.append(actor_rigid_body_states)\n\n        return torch.tensor(obs, dtype=torch.float32)\n\n    def close(self):\n        """Close the simulation"""\n        if self.viewer:\n            self.gym.destroy_viewer(self.viewer)\n        self.gym.destroy_sim(self.sim)\n')),(0,o.yg)("h2",{id:"best-practices-for-simulation"},"Best Practices for Simulation"),(0,o.yg)("h3",{id:"model-accuracy"},"Model Accuracy"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-python"},"# Tips for creating accurate simulation models\n\n# 1. Proper mass and inertia properties\ndef calculate_inertia_solid_cylinder(mass, radius, length):\n    \"\"\"Calculate inertia tensor for a solid cylinder\"\"\"\n    # For a cylinder aligned along z-axis\n    ixx = (1/12) * mass * (3 * radius**2 + length**2)\n    iyy = ixx  # Ixx = Iyy for cylinder\n    izz = (1/2) * mass * radius**2\n\n    return np.array([ixx, iyy, izz, 0, 0, 0])  # Ixx, Iyy, Izz, Ixy, Ixz, Iyz\n\n# 2. Realistic joint limits and dynamics\ndef create_realistic_joint_params(joint_type, joint_name):\n    \"\"\"Create realistic joint parameters based on joint type\"\"\"\n    params = {}\n\n    if joint_type == \"hip\":\n        params['range'] = (-45, 90)  # degrees\n        params['max_effort'] = 200   # N*m\n        params['max_velocity'] = 3   # rad/s\n        params['damping'] = 2.0\n        params['friction'] = 0.5\n    elif joint_type == \"knee\":\n        params['range'] = (-150, 0)  # degrees\n        params['max_effort'] = 150\n        params['max_velocity'] = 4\n        params['damping'] = 1.5\n        params['friction'] = 0.3\n    elif joint_type == \"ankle\":\n        params['range'] = (-30, 30)  # degrees\n        params['max_effort'] = 50\n        params['max_velocity'] = 5\n        params['damping'] = 0.8\n        params['friction'] = 0.2\n    else:\n        # Default values\n        params['range'] = (-90, 90)\n        params['max_effort'] = 100\n        params['max_velocity'] = 2\n        params['damping'] = 1.0\n        params['friction'] = 0.1\n\n    return params\n\n# 3. Sensor noise modeling\nclass NoisySensor:\n    \"\"\"Add realistic noise to sensor readings\"\"\"\n    def __init__(self, mean=0.0, std_dev=0.01, bias=0.0):\n        self.mean = mean\n        self.std_dev = std_dev\n        self.bias = bias\n\n    def add_noise(self, true_value):\n        \"\"\"Add noise to a true sensor value\"\"\"\n        noise = np.random.normal(self.mean, self.std_dev)\n        return true_value + self.bias + noise\n\n# Example usage\nposition_sensor = NoisySensor(mean=0.0, std_dev=0.001, bias=0.0005)  # 1mm std dev, 0.5mm bias\nnoisy_reading = position_sensor.add_noise(1.234)  # True value was 1.234m\n")),(0,o.yg)("h3",{id:"simulation-fidelity-considerations"},"Simulation Fidelity Considerations"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-python"},"# Guidelines for simulation fidelity\n\nclass SimulationFidelityManager:\n    \"\"\"Manage different levels of simulation fidelity\"\"\"\n\n    def __init__(self):\n        self.fidelity_levels = {\n            'fast_research': {\n                'timestep': 0.01,\n                'solver_iterations': 10,\n                'contact_approximation': 'mesh',\n                'sensor_noise': 0.05,\n                'actuator_delay': 0.02\n            },\n            'accurate_validation': {\n                'timestep': 0.001,\n                'solver_iterations': 100,\n                'contact_approximation': 'convex',\n                'sensor_noise': 0.01,\n                'actuator_delay': 0.005\n            },\n            'hardware_test': {\n                'timestep': 0.002,\n                'solver_iterations': 50,\n                'contact_approximation': 'convex',\n                'sensor_noise': 0.02,\n                'actuator_delay': 0.01\n            }\n        }\n\n    def set_fidelity(self, level='accurate_validation'):\n        \"\"\"Set simulation parameters based on fidelity level\"\"\"\n        if level not in self.fidelity_levels:\n            raise ValueError(f\"Unknown fidelity level: {level}\")\n\n        params = self.fidelity_levels[level]\n        print(f\"Setting fidelity to {level}: {params}\")\n        return params\n\n# Usage\nfidelity_manager = SimulationFidelityManager()\nparams = fidelity_manager.set_fidelity('fast_research')\n")),(0,o.yg)("h2",{id:"learning-objectives"},"Learning Objectives"),(0,o.yg)("p",null,"After completing this tutorial, you should be able to:"),(0,o.yg)("ol",null,(0,o.yg)("li",{parentName:"ol"},"Set up and configure different simulation environments (Gazebo, PyBullet, Mujoco)"),(0,o.yg)("li",{parentName:"ol"},"Create robot models in URDF/SDF/XML formats"),(0,o.yg)("li",{parentName:"ol"},"Implement basic control algorithms in simulation"),(0,o.yg)("li",{parentName:"ol"},"Understand the trade-offs between different simulation environments"),(0,o.yg)("li",{parentName:"ol"},"Apply best practices for realistic simulation modeling"),(0,o.yg)("li",{parentName:"ol"},"Integrate simulation with reinforcement learning frameworks")),(0,o.yg)("h2",{id:"hands-on-exercise"},"Hands-On Exercise"),(0,o.yg)("p",null,"Create a simple walking controller for a humanoid robot in your chosen simulation environment:"),(0,o.yg)("ol",null,(0,o.yg)("li",{parentName:"ol"},"Choose one simulation environment (Gazebo, PyBullet, or Mujoco)"),(0,o.yg)("li",{parentName:"ol"},"Create or use an existing humanoid robot model"),(0,o.yg)("li",{parentName:"ol"},"Implement a simple walking gait pattern"),(0,o.yg)("li",{parentName:"ol"},"Add sensors (IMU, joint encoders) to the robot"),(0,o.yg)("li",{parentName:"ol"},"Implement a basic balance controller"),(0,o.yg)("li",{parentName:"ol"},"Test the controller in simulation and analyze the results")),(0,o.yg)("p",null,"This exercise will help you understand the practical aspects of simulation-based robot development and control."))}c.isMDXComponent=!0}}]);