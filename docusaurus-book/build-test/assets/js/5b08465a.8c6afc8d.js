"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[910],{12188:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>s,contentTitle:()=>l,default:()=>p,frontMatter:()=>a,metadata:()=>i,toc:()=>c});var t=o(58168),r=(o(96540),o(15680));const a={id:"control-systems",title:"Control Systems for Humanoid Robots",sidebar_label:"Control Systems"},l="Control Systems for Humanoid Robots",i={unversionedId:"humanoid-robotics/control-systems",id:"humanoid-robotics/control-systems",title:"Control Systems for Humanoid Robots",description:"Introduction to Humanoid Control Systems",source:"@site/docs/humanoid-robotics/control-systems.md",sourceDirName:"humanoid-robotics",slug:"/humanoid-robotics/control-systems",permalink:"/ai-book/docs/humanoid-robotics/control-systems",draft:!1,editUrl:"https://github.com/ayeshalee88/ai-book/edit/main/docusaurus-book/docs/humanoid-robotics/control-systems.md",tags:[],version:"current",frontMatter:{id:"control-systems",title:"Control Systems for Humanoid Robots",sidebar_label:"Control Systems"},sidebar:"tutorialSidebar",previous:{title:"Kinematics",permalink:"/ai-book/docs/humanoid-robotics/kinematics"},next:{title:"ML for Locomotion",permalink:"/ai-book/docs/ai-integration/ml-locomotion"}},s={},c=[{value:"Introduction to Humanoid Control Systems",id:"introduction-to-humanoid-control-systems",level:2},{value:"Control System Architecture",id:"control-system-architecture",level:3},{value:"Low-Level Joint Control",id:"low-level-joint-control",level:3},{value:"PID Control for Joints",id:"pid-control-for-joints",level:4},{value:"Advanced Joint Control",id:"advanced-joint-control",level:4},{value:"Balance and Posture Control",id:"balance-and-posture-control",level:3},{value:"Zero Moment Point (ZMP) Control",id:"zero-moment-point-zmp-control",level:4},{value:"Linear Inverted Pendulum Model (LIPM)",id:"linear-inverted-pendulum-model-lipm",level:4},{value:"Walking Pattern Generation",id:"walking-pattern-generation",level:3},{value:"Preview Control for Walking",id:"preview-control-for-walking",level:4},{value:"Whole-Body Control",id:"whole-body-control",level:3},{value:"Operational Space Control",id:"operational-space-control",level:4},{value:"Model-Based Control",id:"model-based-control",level:3},{value:"Computed Torque Control",id:"computed-torque-control",level:4},{value:"Adaptive and Learning-Based Control",id:"adaptive-and-learning-based-control",level:3},{value:"Model Reference Adaptive Control (MRAC)",id:"model-reference-adaptive-control-mrac",level:4},{value:"Safety and Compliance Control",id:"safety-and-compliance-control",level:3},{value:"Active Compliance for Human Safety",id:"active-compliance-for-human-safety",level:4},{value:"Control Implementation Considerations",id:"control-implementation-considerations",level:3},{value:"Real-Time Performance",id:"real-time-performance",level:4},{value:"Practical Control Strategies",id:"practical-control-strategies",level:3},{value:"Hierarchical Task Control",id:"hierarchical-task-control",level:4},{value:"Learning Objectives",id:"learning-objectives",level:3},{value:"Hands-On Exercise",id:"hands-on-exercise",level:3}],d={toc:c},m="wrapper";function p({components:e,...n}){return(0,r.yg)(m,(0,t.A)({},d,n,{components:e,mdxType:"MDXLayout"}),(0,r.yg)("h1",{id:"control-systems-for-humanoid-robots"},"Control Systems for Humanoid Robots"),(0,r.yg)("h2",{id:"introduction-to-humanoid-control-systems"},"Introduction to Humanoid Control Systems"),(0,r.yg)("p",null,"Controlling humanoid robots presents unique challenges due to their complex dynamics, multiple degrees of freedom, and need for stable interaction with the environment. Unlike simpler robots, humanoid systems must maintain balance while performing tasks, handle complex contact interactions, and operate safely around humans."),(0,r.yg)("h3",{id:"control-system-architecture"},"Control System Architecture"),(0,r.yg)("p",null,"Humanoid control systems typically employ a hierarchical architecture with multiple control layers operating at different timescales:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre"},"High-Level Planning (seconds) - Task planning, path planning\n    \u2193\nBehavior Control (hundreds of ms) - Gait generation, motion selection\n    \u2193\nMotion Control (tens of ms) - Trajectory tracking, balance control\n    \u2193\nLow-Level Control (ms) - Joint control, motor control\n")),(0,r.yg)("h3",{id:"low-level-joint-control"},"Low-Level Joint Control"),(0,r.yg)("h4",{id:"pid-control-for-joints"},"PID Control for Joints"),(0,r.yg)("p",null,"Proportional-Integral-Derivative (PID) controllers form the foundation of joint control:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"class PIDController:\n    def __init__(self, kp, ki, kd, dt=0.001):\n        self.kp = kp\n        self.ki = ki\n        self.kd = kd\n        self.dt = dt\n        self.integral = 0\n        self.prev_error = 0\n\n    def update(self, setpoint, measurement):\n        error = setpoint - measurement\n\n        # Proportional term\n        p_term = self.kp * error\n\n        # Integral term\n        self.integral += error * self.dt\n        i_term = self.ki * self.integral\n\n        # Derivative term\n        derivative = (error - self.prev_error) / self.dt\n        d_term = self.kd * derivative\n\n        self.prev_error = error\n\n        output = p_term + i_term + d_term\n        return output\n\n# Example usage for a single joint\njoint_controller = PIDController(kp=100, ki=1, kd=10, dt=0.001)\ncommanded_position = 1.5  # radians\ncurrent_position = 1.2    # radians\ntorque_command = joint_controller.update(commanded_position, current_position)\n")),(0,r.yg)("h4",{id:"advanced-joint-control"},"Advanced Joint Control"),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Impedance Control:"),"\nImplements virtual spring-damper systems for safe interaction:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"class ImpedanceController:\n    def __init__(self, stiffness, damping, dt=0.001):\n        self.stiffness = stiffness  # N*m/rad or N/rad\n        self.damping = damping      # N*m*s/rad or N*s/rad\n        self.dt = dt\n\n    def update(self, desired_pos, actual_pos, desired_vel=0, actual_vel=0):\n        pos_error = desired_pos - actual_pos\n        vel_error = desired_vel - actual_vel\n\n        # Impedance control law: F = K(x_d - x) + B(v_d - v)\n        force = self.stiffness * pos_error + self.damping * vel_error\n        return force\n\n# Example: Compliant joint control\ncompliant_controller = ImpedanceController(stiffness=50, damping=10)\ncompliant_torque = compliant_controller.update(\n    desired_pos=0.0,\n    actual_pos=0.1,\n    desired_vel=0.0,\n    actual_vel=0.05\n)\n")),(0,r.yg)("h3",{id:"balance-and-posture-control"},"Balance and Posture Control"),(0,r.yg)("h4",{id:"zero-moment-point-zmp-control"},"Zero Moment Point (ZMP) Control"),(0,r.yg)("p",null,"The ZMP is crucial for stable bipedal locomotion:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'import numpy as np\n\nclass ZMPController:\n    def __init__(self, robot_height, gravity=9.81):\n        self.h = robot_height  # CoM height\n        self.g = gravity       # gravitational acceleration\n\n    def compute_zmp(self, com_pos, com_acc):\n        """\n        Compute ZMP from CoM position and acceleration\n        zmp_x = com_x - h/g * com_acc_x\n        zmp_y = com_y - h/g * com_acc_y\n        """\n        zmp = com_pos - (self.h / self.g) * com_acc\n        return zmp\n\n    def track_zmp(self, desired_zmp, current_com_pos, current_com_acc, kp=1.0):\n        """\n        Control CoM to track desired ZMP\n        """\n        current_zmp = self.compute_zmp(current_com_pos, current_com_acc)\n        zmp_error = desired_zmp - current_zmp\n\n        # Adjust CoM acceleration to reduce ZMP error\n        com_acc_correction = kp * zmp_error\n        desired_com_acc = current_com_acc + com_acc_correction\n\n        return desired_com_acc\n')),(0,r.yg)("h4",{id:"linear-inverted-pendulum-model-lipm"},"Linear Inverted Pendulum Model (LIPM)"),(0,r.yg)("p",null,"A simplified model for balance control:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'class LIPMController:\n    def __init__(self, com_height, gravity=9.81):\n        self.h = com_height\n        self.g = gravity\n        self.omega = np.sqrt(self.g / self.h)\n\n    def compute_next_com_state(self, current_com_pos, current_com_vel,\n                              zmp_pos, dt):\n        """\n        Compute next CoM state using LIPM\n        """\n        # State transition equations for LIPM\n        A = np.array([\n            [np.cosh(self.omega * dt), (1/self.omega) * np.sinh(self.omega * dt)],\n            [self.omega * np.sinh(self.omega * dt), np.cosh(self.omega * dt)]\n        ])\n\n        state = np.array([current_com_pos, current_com_vel])\n        zmp_influence = np.array([\n            -zmp_pos * (1 - np.cosh(self.omega * dt)),\n            -zmp_pos * self.omega * np.sinh(self.omega * dt)\n        ])\n\n        next_state = A @ state + zmp_influence\n        return next_state[0], next_state[1]  # next_pos, next_vel\n')),(0,r.yg)("h3",{id:"walking-pattern-generation"},"Walking Pattern Generation"),(0,r.yg)("h4",{id:"preview-control-for-walking"},"Preview Control for Walking"),(0,r.yg)("p",null,"Preview control uses future reference trajectories to improve tracking:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'class PreviewController:\n    def __init__(self, dt, preview_steps, com_height, gravity=9.81):\n        self.dt = dt\n        self.preview_steps = preview_steps\n        self.h = com_height\n        self.g = gravity\n        self.omega = np.sqrt(self.g / self.h)\n\n        # Compute preview gains\n        self.compute_preview_gains()\n\n    def compute_preview_gains(self):\n        """Compute gains for preview control"""\n        # This is a simplified version - full implementation requires\n        # solving Riccati equations for optimal control\n        self.k_pos = 1.0\n        self.k_vel = 1.0\n        self.preview_gains = np.zeros(self.preview_steps)\n\n        # Compute preview gains based on system dynamics\n        for i in range(self.preview_steps):\n            time_ahead = (i + 1) * self.dt\n            self.preview_gains[i] = np.exp(-self.omega * time_ahead)\n\n    def compute_control(self, current_com_pos, current_com_vel,\n                       reference_trajectory):\n        """\n        Compute control using current state and preview of future references\n        """\n        # Current state error feedback\n        control = self.k_pos * (reference_trajectory[0] - current_com_pos) + \\\n                  self.k_vel * (-current_com_vel)\n\n        # Preview compensation\n        for i in range(min(len(reference_trajectory)-1, self.preview_steps)):\n            control += self.preview_gains[i] * reference_trajectory[i+1]\n\n        return control\n')),(0,r.yg)("h3",{id:"whole-body-control"},"Whole-Body Control"),(0,r.yg)("h4",{id:"operational-space-control"},"Operational Space Control"),(0,r.yg)("p",null,"Controls end-effectors while maintaining balance:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'class OperationalSpaceController:\n    def __init__(self, robot_model):\n        self.model = robot_model  # Robot model with kinematics/dynamics\n\n    def compute_torques(self, task_desired_acc, base_desired_acc,\n                       joint_pos, joint_vel):\n        """\n        Compute joint torques using operational space control\n        """\n        # Get Jacobians and mass matrix from robot model\n        J_task = self.model.jacobian_task(joint_pos)  # Task space Jacobian\n        J_base = self.model.jacobian_base(joint_pos)  # Base (CoM) Jacobian\n        M = self.model.mass_matrix(joint_pos)         # Joint space mass matrix\n\n        # Compute operational space mass matrices\n        Lambda_task = np.linalg.inv(J_task @ np.linalg.inv(M) @ J_task.T)\n        Lambda_base = np.linalg.inv(J_base @ np.linalg.inv(M) @ J_base.T)\n\n        # Compute bias forces\n        h = self.model.bias_forces(joint_pos, joint_vel)\n\n        # Compute task and base torques\n        tau_task = J_task.T @ Lambda_task @ (task_desired_acc +\n                   self.model.task_bias_acc(joint_pos, joint_vel))\n        tau_base = J_base.T @ Lambda_base @ (base_desired_acc +\n                   self.model.base_bias_acc(joint_pos, joint_vel))\n\n        # Combine torques with null-space projection\n        I = np.eye(M.shape[0])\n        N_task = I - np.linalg.inv(M) @ J_task.T @ Lambda_task @ J_task\n        tau = tau_task + N_task @ tau_base + h\n\n        return tau\n')),(0,r.yg)("h3",{id:"model-based-control"},"Model-Based Control"),(0,r.yg)("h4",{id:"computed-torque-control"},"Computed Torque Control"),(0,r.yg)("p",null,"Linearizes the robot dynamics for easier control:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'class ComputedTorqueController:\n    def __init__(self, robot_model, kp_diag, kd_diag):\n        self.model = robot_model\n        self.kp = np.diag(kp_diag)  # Proportional gains\n        self.kd = np.diag(kd_diag)  # Derivative gains\n\n    def compute_control(self, q_desired, qd_desired, qdd_desired,\n                       q_current, qd_current):\n        """\n        Compute control torques using computed torque method\n        """\n        # Get robot dynamics\n        M = self.model.mass_matrix(q_current)\n        C = self.model.coriolis_matrix(q_current, qd_current)\n        G = self.model.gravity_vector(q_current)\n\n        # Compute desired acceleration in joint space\n        q_error = q_desired - q_current\n        qd_error = qd_desired - qd_current\n\n        # Feedforward + feedback control\n        qdd_cmd = qdd_desired + self.kp @ q_error + self.kd @ qd_error\n\n        # Computed torque control law\n        tau = M @ qdd_cmd + C @ qd_current + G\n\n        return tau\n')),(0,r.yg)("h3",{id:"adaptive-and-learning-based-control"},"Adaptive and Learning-Based Control"),(0,r.yg)("h4",{id:"model-reference-adaptive-control-mrac"},"Model Reference Adaptive Control (MRAC)"),(0,r.yg)("p",null,"Adapts to model uncertainties:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'class MRACController:\n    def __init__(self, reference_model_params, adaptation_rate=0.01):\n        self.ref_params = reference_model_params\n        self.gamma = adaptation_rate\n        self.theta = np.zeros(len(reference_model_params))  # Adaptive parameters\n\n    def update(self, state_error, reference_state, current_state):\n        """\n        Update adaptive parameters based on tracking error\n        """\n        # Update adaptive parameters\n        self.theta += self.gamma * state_error * reference_state\n\n        # Apply parameter adaptation to control law\n        adapted_control = self.compute_adapted_control(current_state, self.theta)\n\n        return adapted_control\n\n    def compute_adapted_control(self, state, params):\n        """\n        Compute control with adapted parameters\n        """\n        # Simplified example - actual implementation depends on system\n        return -params @ state\n')),(0,r.yg)("h3",{id:"safety-and-compliance-control"},"Safety and Compliance Control"),(0,r.yg)("h4",{id:"active-compliance-for-human-safety"},"Active Compliance for Human Safety"),(0,r.yg)("p",null,"Ensures safe interaction with humans:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'class SafetyController:\n    def __init__(self, max_force_threshold=50.0,  # Newtons\n                 max_torque_threshold=10.0):      # N*m\n        self.max_force = max_force_threshold\n        self.max_torque = max_torque_threshold\n\n    def limit_forces(self, commanded_force, sensed_force=None):\n        """\n        Limit forces to safe levels\n        """\n        if sensed_force is not None and np.linalg.norm(sensed_force) > self.max_force:\n            # Emergency stop or compliant behavior\n            return np.zeros_like(commanded_force)\n\n        # Limit commanded forces\n        force_norm = np.linalg.norm(commanded_force)\n        if force_norm > self.max_force:\n            commanded_force = (commanded_force / force_norm) * self.max_force\n\n        return commanded_force\n\n    def emergency_stop(self, sensor_data):\n        """\n        Check for emergency conditions\n        """\n        # Check for collision, excessive force, etc.\n        if (sensor_data.get(\'collision_detected\', False) or\n            sensor_data.get(\'excessive_force\', False)):\n            return True\n        return False\n')),(0,r.yg)("h3",{id:"control-implementation-considerations"},"Control Implementation Considerations"),(0,r.yg)("h4",{id:"real-time-performance"},"Real-Time Performance"),(0,r.yg)("p",null,"For stable control, timing is critical:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'import time\nimport threading\n\nclass RealTimeController:\n    def __init__(self, control_frequency=1000):  # Hz\n        self.dt = 1.0 / control_frequency\n        self.next_update = time.time()\n        self.is_running = False\n\n    def run_control_loop(self, control_callback, sensor_callback):\n        """\n        Run control loop with precise timing\n        """\n        self.is_running = True\n\n        while self.is_running:\n            start_time = time.time()\n\n            # Read sensors\n            sensor_data = sensor_callback()\n\n            # Execute control\n            control_commands = control_callback(sensor_data)\n\n            # Apply commands\n            self.apply_commands(control_commands)\n\n            # Wait for next cycle\n            elapsed = time.time() - start_time\n            sleep_time = self.dt - elapsed\n\n            if sleep_time > 0:\n                time.sleep(sleep_time)\n            else:\n                print(f"Control loop exceeded timing budget by {abs(sleep_time)*1000:.1f}ms")\n\n    def apply_commands(self, commands):\n        """\n        Apply control commands to hardware\n        """\n        # Interface with robot hardware\n        pass\n')),(0,r.yg)("h3",{id:"practical-control-strategies"},"Practical Control Strategies"),(0,r.yg)("h4",{id:"hierarchical-task-control"},"Hierarchical Task Control"),(0,r.yg)("p",null,"Manages multiple simultaneous objectives:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"class HierarchicalController:\n    def __init__(self):\n        self.tasks = []  # List of tasks with priorities\n\n    def add_task(self, task_function, priority, weight=1.0):\n        \"\"\"\n        Add a control task with priority and weight\n        \"\"\"\n        self.tasks.append({\n            'function': task_function,\n            'priority': priority,\n            'weight': weight\n        })\n\n        # Sort by priority (lower number = higher priority)\n        self.tasks.sort(key=lambda x: x['priority'])\n\n    def compute_control(self, robot_state):\n        \"\"\"\n        Compute control using hierarchical task prioritization\n        \"\"\"\n        total_control = np.zeros(robot_state.joint_count)\n\n        for task in self.tasks:\n            # Compute task-specific control\n            task_control = task['function'](robot_state)\n\n            # Apply task weight\n            task_control *= task['weight']\n\n            # Add to total control (with priority-based blending)\n            total_control += task_control\n\n        return total_control\n")),(0,r.yg)("h3",{id:"learning-objectives"},"Learning Objectives"),(0,r.yg)("p",null,"After studying this chapter, you should be able to:"),(0,r.yg)("ol",null,(0,r.yg)("li",{parentName:"ol"},"Implement PID and advanced joint control algorithms"),(0,r.yg)("li",{parentName:"ol"},"Design balance and posture controllers for humanoid robots"),(0,r.yg)("li",{parentName:"ol"},"Generate stable walking patterns using ZMP and LIPM"),(0,r.yg)("li",{parentName:"ol"},"Apply operational space control for whole-body coordination"),(0,r.yg)("li",{parentName:"ol"},"Implement safety and compliance control strategies"),(0,r.yg)("li",{parentName:"ol"},"Design hierarchical control architectures"),(0,r.yg)("li",{parentName:"ol"},"Consider real-time implementation constraints")),(0,r.yg)("h3",{id:"hands-on-exercise"},"Hands-On Exercise"),(0,r.yg)("p",null,"Implement a simple balance controller for a 2D inverted pendulum model:"),(0,r.yg)("ol",null,(0,r.yg)("li",{parentName:"ol"},"Create a simulation of an inverted pendulum"),(0,r.yg)("li",{parentName:"ol"},"Implement a ZMP-based balance controller"),(0,r.yg)("li",{parentName:"ol"},"Test with external disturbances"),(0,r.yg)("li",{parentName:"ol"},"Analyze stability and performance"),(0,r.yg)("li",{parentName:"ol"},"Extend to 3D for more realistic humanoid balance")),(0,r.yg)("p",null,"This exercise will help you understand the practical challenges of balance control in humanoid robots."))}p.isMDXComponent=!0},15680:(e,n,o)=>{o.d(n,{xA:()=>d,yg:()=>_});var t=o(96540);function r(e,n,o){return n in e?Object.defineProperty(e,n,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[n]=o,e}function a(e,n){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter(function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable})),o.push.apply(o,t)}return o}function l(e){for(var n=1;n<arguments.length;n++){var o=null!=arguments[n]?arguments[n]:{};n%2?a(Object(o),!0).forEach(function(n){r(e,n,o[n])}):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):a(Object(o)).forEach(function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(o,n))})}return e}function i(e,n){if(null==e)return{};var o,t,r=function(e,n){if(null==e)return{};var o,t,r={},a=Object.keys(e);for(t=0;t<a.length;t++)o=a[t],n.indexOf(o)>=0||(r[o]=e[o]);return r}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(t=0;t<a.length;t++)o=a[t],n.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(r[o]=e[o])}return r}var s=t.createContext({}),c=function(e){var n=t.useContext(s),o=n;return e&&(o="function"==typeof e?e(n):l(l({},n),e)),o},d=function(e){var n=c(e.components);return t.createElement(s.Provider,{value:n},e.children)},m="mdxType",p={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},u=t.forwardRef(function(e,n){var o=e.components,r=e.mdxType,a=e.originalType,s=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),m=c(o),u=r,_=m["".concat(s,".").concat(u)]||m[u]||p[u]||a;return o?t.createElement(_,l(l({ref:n},d),{},{components:o})):t.createElement(_,l({ref:n},d))});function _(e,n){var o=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var a=o.length,l=new Array(a);l[0]=u;var i={};for(var s in n)hasOwnProperty.call(n,s)&&(i[s]=n[s]);i.originalType=e,i[m]="string"==typeof e?e:r,l[1]=i;for(var c=2;c<a;c++)l[c]=o[c];return t.createElement.apply(null,l)}return t.createElement.apply(null,o)}u.displayName="MDXCreateElement"}}]);